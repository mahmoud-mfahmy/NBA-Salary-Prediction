{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings;\n",
    "warnings.filterwarnings('ignore');\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('statsandsal_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dummy columns for the one categorical variable: Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop('Salary', axis=1)\n",
    "y = df.Salary.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now standardize the salary in y_train so that all are on a salary cap of $100,000,000 (See Data_PreProcessing notebook for explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide 100 by the salary cap of that year to get \n",
    "# standardizaton factor\n",
    "caps = {\n",
    "2012: 100/58.044000,\t\n",
    "2013: 100/58.044000,\t\n",
    "2014: 100/58.679000,\t\n",
    "2015: 100/63.065000,\t\n",
    "2016: 100/70.000000,\t\n",
    "2017: 100/94.143000,\t\n",
    "2018: 100/99.093000,\t\n",
    "2019: 100/101.869000,\t\n",
    "2020: 100/109.140000\t\n",
    "        }\n",
    "# Create temporary dataframe to map factors to y_train\n",
    "yvals = list(pd.Series(y_train).values)\n",
    "dates = list(X_train['Date'].values)\n",
    "temp = pd.DataFrame({'Salary':yvals,'Date':dates})\n",
    "temp['Factor'] = temp['Date'].map(caps)\n",
    "temp['Salary'] = temp['Salary'] * temp['Factor']\n",
    "y_train = np.array(temp['Salary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform linear regression using two packages:\n",
    "- Statsmodels to evaluate model coefficients\n",
    "- Sklearn for predictions\n",
    "\n",
    "We will use mean absolute error as our performance metric throughout as it is intuitive to interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Statsmodels Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.563\n",
      "Model:                            OLS   Adj. R-squared:                  0.557\n",
      "Method:                 Least Squares   F-statistic:                     97.46\n",
      "Date:                Mon, 21 Dec 2020   Prob (F-statistic):               0.00\n",
      "Time:                        17:22:53   Log-Likelihood:                -11442.\n",
      "No. Observations:                3990   AIC:                         2.299e+04\n",
      "Df Residuals:                    3937   BIC:                         2.332e+04\n",
      "Df Model:                          52                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       -576.1661     58.477     -9.853      0.000    -690.815    -461.517\n",
      "Age            0.3566      0.017     20.810      0.000       0.323       0.390\n",
      "G              0.0101      0.010      1.020      0.308      -0.009       0.030\n",
      "GS             0.0378      0.005      7.157      0.000       0.027       0.048\n",
      "MP            -0.0606      0.051     -1.192      0.233      -0.160       0.039\n",
      "FG             2.9892      2.227      1.342      0.180      -1.377       7.356\n",
      "FGA            4.5669      1.483      3.079      0.002       1.659       7.475\n",
      "FG%           12.8487     10.336      1.243      0.214      -7.416      33.113\n",
      "3P            -0.8692      2.004     -0.434      0.665      -4.798       3.060\n",
      "3PA           -3.7763      1.485     -2.543      0.011      -6.688      -0.864\n",
      "3P%            0.2621      0.681      0.385      0.700      -1.072       1.597\n",
      "2P            -0.3146      1.624     -0.194      0.846      -3.498       2.869\n",
      "2PA           -4.9290      1.484     -3.320      0.001      -7.839      -2.019\n",
      "2P%           -2.2344      1.845     -1.211      0.226      -5.852       1.383\n",
      "eFG%          -3.8012     10.275     -0.370      0.711     -23.945      16.343\n",
      "FT             2.2129      0.997      2.219      0.027       0.258       4.168\n",
      "FTA           -0.4795      0.375     -1.279      0.201      -1.215       0.256\n",
      "FT%           -0.6860      0.645     -1.064      0.287      -1.950       0.578\n",
      "ORB           -0.5504      1.420     -0.388      0.698      -3.334       2.233\n",
      "DRB           -0.0007      1.415     -0.000      1.000      -2.774       2.773\n",
      "TRB            0.9685      1.405      0.689      0.491      -1.785       3.722\n",
      "AST            1.4982      0.178      8.400      0.000       1.149       1.848\n",
      "STL           -0.6249      0.503     -1.243      0.214      -1.610       0.361\n",
      "BLK            1.0377      0.438      2.369      0.018       0.179       1.896\n",
      "TOV           -0.9417      0.384     -2.449      0.014      -1.695      -0.188\n",
      "PF            -1.5754      0.198     -7.971      0.000      -1.963      -1.188\n",
      "PTS           -0.5100      0.943     -0.541      0.589      -2.358       1.338\n",
      "Date           0.3399      0.035      9.772      0.000       0.272       0.408\n",
      "PER           -0.2208      0.100     -2.215      0.027      -0.416      -0.025\n",
      "TS%           -6.4990      5.875     -1.106      0.269     -18.017       5.019\n",
      "3PAr          -0.4319      1.653     -0.261      0.794      -3.673       2.809\n",
      "FTr            0.1554      0.786      0.198      0.843      -1.385       1.696\n",
      "ORB%           0.3556      0.290      1.225      0.220      -0.213       0.925\n",
      "DRB%           0.2418      0.282      0.858      0.391      -0.310       0.794\n",
      "TRB%          -0.6527      0.563     -1.159      0.247      -1.757       0.452\n",
      "AST%          -0.0829      0.026     -3.199      0.001      -0.134      -0.032\n",
      "STL%           0.0882      0.177      0.498      0.619      -0.259       0.436\n",
      "BLK%          -0.1410      0.101     -1.393      0.164      -0.339       0.057\n",
      "TOV%           0.0353      0.022      1.587      0.113      -0.008       0.079\n",
      "USG%           0.0997      0.051      1.952      0.051      -0.000       0.200\n",
      "OWS           -0.4371      1.392     -0.314      0.754      -3.166       2.292\n",
      "DWS           -0.0857      1.395     -0.061      0.951      -2.820       2.648\n",
      "WS             0.7300      1.392      0.524      0.600      -2.000       3.459\n",
      "WS/48          2.3504      5.528      0.425      0.671      -8.487      13.188\n",
      "OBPM          -0.7886      1.364     -0.578      0.563      -3.463       1.886\n",
      "DBPM          -0.4606      1.365     -0.338      0.736      -3.136       2.215\n",
      "BPM            0.8122      1.362      0.596      0.551      -1.859       3.483\n",
      "VORP          -0.8785      0.280     -3.141      0.002      -1.427      -0.330\n",
      "Tot_Mins      -0.0023      0.001     -4.245      0.000      -0.003      -0.001\n",
      "Pos_C       -114.2079     11.707     -9.755      0.000    -137.161     -91.255\n",
      "Pos_PF      -114.6620     11.697     -9.803      0.000    -137.595     -91.729\n",
      "Pos_PG      -116.6417     11.699     -9.970      0.000    -139.578     -93.706\n",
      "Pos_SF      -115.1150     11.686     -9.850      0.000    -138.027     -92.203\n",
      "Pos_SG      -115.5395     11.697     -9.878      0.000    -138.471     -92.608\n",
      "==============================================================================\n",
      "Omnibus:                      548.587   Durbin-Watson:                   1.956\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1576.322\n",
      "Skew:                           0.732   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.709   Cond. No.                     2.47e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 3.77e-21. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X_sm  = sm.add_constant(X)\n",
    "model = sm.OLS(y,X_sm)\n",
    "results = model.fit().summary()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The current model explains 56.3% of the variance in player salary\n",
    "- There is significant multicollinearity as expected, so it is difficult to assess feature importance\n",
    "\n",
    "\n",
    "Check multicollinearity using VIF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variables</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>1.174151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G</td>\n",
       "      <td>11.535912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GS</td>\n",
       "      <td>4.784511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MP</td>\n",
       "      <td>45.929810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FG</td>\n",
       "      <td>4854.431688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FGA</td>\n",
       "      <td>9598.688488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FG%</td>\n",
       "      <td>188.657369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3P</td>\n",
       "      <td>495.928222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3PA</td>\n",
       "      <td>1860.451967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3P%</td>\n",
       "      <td>2.501490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2P</td>\n",
       "      <td>1930.512763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2PA</td>\n",
       "      <td>6052.067804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2P%</td>\n",
       "      <td>7.299979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>eFG%</td>\n",
       "      <td>182.655930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FT</td>\n",
       "      <td>393.083944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FTA</td>\n",
       "      <td>85.194499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FT%</td>\n",
       "      <td>2.880446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ORB</td>\n",
       "      <td>287.205699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DRB</td>\n",
       "      <td>1407.868122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TRB</td>\n",
       "      <td>2600.385286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AST</td>\n",
       "      <td>22.674824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>STL</td>\n",
       "      <td>9.920438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BLK</td>\n",
       "      <td>7.975459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>TOV</td>\n",
       "      <td>20.144347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PF</td>\n",
       "      <td>4.509414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PTS</td>\n",
       "      <td>6625.263031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Date</td>\n",
       "      <td>1.751342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PER</td>\n",
       "      <td>76.460460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>TS%</td>\n",
       "      <td>56.063166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3PAr</td>\n",
       "      <td>28.209372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>FTr</td>\n",
       "      <td>3.690362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ORB%</td>\n",
       "      <td>346.516141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>DRB%</td>\n",
       "      <td>723.158986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>TRB%</td>\n",
       "      <td>1639.070633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>AST%</td>\n",
       "      <td>12.581750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>STL%</td>\n",
       "      <td>4.517070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>BLK%</td>\n",
       "      <td>6.559332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TOV%</td>\n",
       "      <td>3.318897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>USG%</td>\n",
       "      <td>16.145339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>OWS</td>\n",
       "      <td>1620.323778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>DWS</td>\n",
       "      <td>513.654537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>WS</td>\n",
       "      <td>3286.288896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>WS/48</td>\n",
       "      <td>57.067778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>OBPM</td>\n",
       "      <td>8240.182822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>DBPM</td>\n",
       "      <td>1161.446798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>BPM</td>\n",
       "      <td>12228.557538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>VORP</td>\n",
       "      <td>28.199348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Tot_Mins</td>\n",
       "      <td>40.917776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Pos_C</td>\n",
       "      <td>216399.575808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Pos_PF</td>\n",
       "      <td>224385.312806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Pos_PG</td>\n",
       "      <td>205087.899120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Pos_SF</td>\n",
       "      <td>192425.312074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Pos_SG</td>\n",
       "      <td>231353.053558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variables            VIF\n",
       "0        Age       1.174151\n",
       "1          G      11.535912\n",
       "2         GS       4.784511\n",
       "3         MP      45.929810\n",
       "4         FG    4854.431688\n",
       "5        FGA    9598.688488\n",
       "6        FG%     188.657369\n",
       "7         3P     495.928222\n",
       "8        3PA    1860.451967\n",
       "9        3P%       2.501490\n",
       "10        2P    1930.512763\n",
       "11       2PA    6052.067804\n",
       "12       2P%       7.299979\n",
       "13      eFG%     182.655930\n",
       "14        FT     393.083944\n",
       "15       FTA      85.194499\n",
       "16       FT%       2.880446\n",
       "17       ORB     287.205699\n",
       "18       DRB    1407.868122\n",
       "19       TRB    2600.385286\n",
       "20       AST      22.674824\n",
       "21       STL       9.920438\n",
       "22       BLK       7.975459\n",
       "23       TOV      20.144347\n",
       "24        PF       4.509414\n",
       "25       PTS    6625.263031\n",
       "26      Date       1.751342\n",
       "27       PER      76.460460\n",
       "28       TS%      56.063166\n",
       "29      3PAr      28.209372\n",
       "30       FTr       3.690362\n",
       "31      ORB%     346.516141\n",
       "32      DRB%     723.158986\n",
       "33      TRB%    1639.070633\n",
       "34      AST%      12.581750\n",
       "35      STL%       4.517070\n",
       "36      BLK%       6.559332\n",
       "37      TOV%       3.318897\n",
       "38      USG%      16.145339\n",
       "39       OWS    1620.323778\n",
       "40       DWS     513.654537\n",
       "41        WS    3286.288896\n",
       "42     WS/48      57.067778\n",
       "43      OBPM    8240.182822\n",
       "44      DBPM    1161.446798\n",
       "45       BPM   12228.557538\n",
       "46      VORP      28.199348\n",
       "47  Tot_Mins      40.917776\n",
       "48     Pos_C  216399.575808\n",
       "49    Pos_PF  224385.312806\n",
       "50    Pos_PG  205087.899120\n",
       "51    Pos_SF  192425.312074\n",
       "52    Pos_SG  231353.053558"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "def calc_vif(X):\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    return(vif)\n",
    "\n",
    "vif = calc_vif(X) \n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our objective is prediction, we will not drop these correlated features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Scikit-learn Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model using the training data and evaluate results using 5-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.79134998 -3.83789897 -3.84999837 -3.68338861 -3.69803466]\n",
      "-3.772134117306016\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train,y_train)\n",
    "lm_res = cross_val_score(lm, X_train, y_train, scoring = 'neg_mean_absolute_error',cv=5)\n",
    "print(lm_res)\n",
    "print(np.mean(lm_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso regression is used for L1 regularization and it will shrink the coefficients of unimportant features to 0. We first build the model using the default parameters and then tune the alpha hyperparameter which multiplies the L1 term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.92607305 -3.9454999  -3.91099838 -3.84958445 -3.87178944]\n",
      "-3.9007890434047896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lm_l = Lasso()\n",
    "lm_l.fit(X_train,y_train)\n",
    "lml_base_res = cross_val_score(lm_l, X_train, y_train, scoring = 'neg_mean_absolute_error',cv=5)\n",
    "print(lml_base_res)\n",
    "print(np.mean(lml_base_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now tune the alpha parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD4CAYAAAAdIcpQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAwGklEQVR4nO3deXhU5fXA8e9JQhZCSFjCEggEZF9CgAiodUEppVrFCiKIolag1LrXaq39qZXaqrTaim0VpW4gqCiKC0pRCy5sCZuALBESwppAdkLIdn5/ZGKnMckEJsmdTM7neeZx7tz33jnvg8zhve8mqooxxhhTmwCnAzDGGOP7LFkYY4zxyJKFMcYYjyxZGGOM8ciShTHGGI+CnA6gPrVv317j4uKcDsMYY5qU5OTkY6oaXVsZv0oWcXFxJCUlOR2GMcY0KSKS5qmMPYYyxhjjkSULY4wxHlmyMMYY45ElC2OMMR5ZsjDGGOORJQtjjDEeWbIwxhjjkVfzLERkNjAeKAcygBtV9VCVMqOBp9w+6gdMVtV3RGQ+kAgIsNt1fYHruknAw4ACW1T1Wm9iNf6vqKSM7YdyySsq5WRxGYXFZZwsLuVkSRkni8uJa9+Ss+PaEhMV5nSoxjQ54s1+FiLSWlXzXO9vBwao6qxayrcFUoCuqlpY5fongQxVfUxEegNvABeraraIdFDVDE/xJCYmqk3Ka14y8ov4bGcGK7/J4Is9xzhZUubxmq5twhgR15YRPSpePdqHIyKNEK0xvklEklU1sbYyXrUsKn/oXcKpaAXUZiKwXFUL3a+Xir+pYW7XzwD+rqrZrnIeE4VpPg7lnGTppoP8e8dRNqfnANAlKoxJiV05v3c0bVsF0zI4kJYtgggLDqRlcCDBQQHsPprP+n1ZrN+Xxardmby96SAAbcODie8aSXzXKOK7RBIfG0mHiFAHa2iM7/GqZQEgIo8C04BcYLSqZtZS9lPgSVV93+2zF4FLgR3AZa4WxztUPJY6DwgEHlbVj2q450xgJkC3bt2Gp6V5nLVumrB3Nx/kgaXbKDhVypDYKMb068CYAR3p1ynitFoHqsreYydYtzeLTfuz2Xoglz0Z+ZS7/jp0jgwlvmskQ7u1YWhsFPFdowgLDmygWhnjrLq0LDwmCxFZCXSq5tQDqvquW7n7gVBVfaiG+3QGtgIxqlpS5VwgMBfYoKovisj7QAkwCegKrAYGq2pObbHaYyj/VXCqlAff3cbbGw8yvHsbnpw0hO7twuv1OwqLS9l+KI+tB3LZeiCHLek5pB4vBCAwQOjfOYJh3dowtFsUF/bpQNvw4Hr9fmOcUi+PoVR1TB2/byHwIVBtsqDih39p1UTh+o4yEVkM3Au8CBwA1rnK7hOR3UBvYEMdYzF+ZOuBHG5ftIn9WYXcfklvbr+4F0GB9T+Qr2VwEGfHteXsuLbffZZ1ophN+7PZuD+bTftzeCv5AK+sSSM4MIAfDerElBGxnNOznfV5GL/n7Wio3qq6x3U4HthZS/EpwP1u1wpwlqqmuN5f4Xb9O67yL4pIe6APsNebWE3TU16uPP/5XuZ8vIsOESEsnnkOI3q09XxhPWobHswl/TtySf+OAJSVKzsO5fHWxgO8vfEA7205RFy7lkwe0Y2Jw7vSvlVIo8ZnTGPxdjTUW0BfKobOpgGzVPWgiCS63k93lYsDvgRiVbXc9VkA8DnQmoqhs1uAX6hqnit5/AUYB5QBj6rqYk/x2GMo/5FTWMxtizbx+Z5j/HhQJx67Kp7Ili2cDut/FJWUsXzbYRatS2d9ahZBAcIPB3RkUmIs5/du3yCtH2MaQr30WTQlliz8Q0pGPje/nMThnCIevmIgU0bE+vxjnpSMfBavT+ftTQfJOlFMh4gQrhrWlasTu3JWdCunwzOmVpYsTJPzn10Z3PbaJkJaBPDc9cMZ3r1xHzt5q7i0nE93ZrAkOZ3PdmVSVq4M796Gq4d35fIhMYSH+NV+Y8ZPWLIwTYaq8uKXqfzhgx307dSa56cNp2ublk6H5ZWM/CKWbjzIm8kHSMkoICIkiKuGdeG6Ud3p3THC6fCM+Y4lC9MkFJeW8+C721i8IZ2xAzry1DUJfvUvcFVl4/5sFqzdzwdbD1NcVs6onm25blR3xg7oRHCQ9W0YZ1myMD4vp7CYma8ms35fFreO7sXdP+xDQIBv909443jBKd5MPsDCdWmkZ50kOiKEX1x4FjecG0egH9fb+DZLFsanHSs4xXUvrGPvsRPMmRjP+IQuTofUaMrKldW7M3nhi718mXKc+K6R/OmqwQyMiXQ6NNMM1SVZWPvXOCIjr4gp89aSevwE829IbFaJAipmhI/u14EFN49k7pShHMo5yRXPfMmfln/DyWLPiyEa09gsWZhGdyS3iMnz1nIw5yQv3jiC83tHOx2SY0SEy4fE8MndFzEpsSvPrdrL2L+uYvXuGpdYM8YRlixMozqQXcik59aQkX+KV342gnPOaud0SD4hsmUL/nRVPK/PHEWLwACm/Ws9dy7exPGCU06HZgxgycI0orTjJ7jmubXkFBazYPpIEuOa1hyKxjCyZzuW33E+d1zSmw++PswPn1rNO5sO4k99i6ZpsmRhGsXezAKueW4tJ4pLeW3GKBJio5wOyWeFBAVy1w/78MHt59O9XUvufH0zN720gQPZhU6HZpoxSxamwR3OPcnUF9ZRUlbO4pmjGNTFRvzURZ+OESyZdS4PXT6A9fuyGPvUal76ch9l5dbKMI3PkoVpULknS7jxXxvILyrllZtH0K9Ta6dDalICA4SbzuvBirsuIDGuLQ+/t4Orn/2KlIwCp0MzzYwlC9NgikrKmPFKEnuPFTDv+uE2h8ALXdu05OWbzuapa4aw99gJLn36c55b9a21MkyjsWRhGkRZuXLX65tZvy+Lv0xK4Nxe7Z0OqckTEX46tCsr7rqAi/pE86flO5lorQzTSCxZmHqnqjzy3naWbzvC7y7rzxVDYpwOya90iAjlueuH87fJCexztTLmrbZWhmlYlixMvfvnqm95eU0aM87vwfTzezodjl8SEcYndGHFXRdwYZ9o/vjhTq5+9iv2HM13OjTjpyxZmHq1JPkAT3y0i/EJMdz/4/5Oh+P3OkSEMs/Vyth77ATj/vY5v39vO7mF39vq3hiveJUsRGS2iGwVkc0iskJEvve8QURGu85XvopE5ErXufkissV1jyUi0sr1eTcR+UxENrnOXepNnKbhqSrPrvqWe5ds4bxe7ZgzcYhfrx7rSypbGZ/cfSHXnB3Ly1+lctGfP2PB2jR7NGXqjbd7cLdW1TzX+9uBAao6q5bybYEUoKuqFla5/kkgQ1UfE5F5wCZV/aeIDAA+VNU4T/HYqrPOKCwu5d4lW3l/62EuG9yZJybG+9V+FE3N9kO5PPLeDtbty6JfpwgeunygLatiatXgq85W/tC7hAOeMs9EYLmqFrpfLxUbLIe5Xa9A5YD8SOCQN3GahrP/eCFX/eMrPvj6MPeN68cz1w61ROGwgTGRLJ45in9MHUZ+USlTnl/LL1/bSPaJYqdDM02Y1/tZiMijwDQgFxitqjUulykinwJPqur7bp+9CFwK7AAuc7U4OgMrgDZUJKExqppcwz1nAjMBunXrNjwtLc2r+pi6+3xPJre+tglVZe61w7iwT/NdPdZXFZWU8dyqvTzz2R7ahgfzl6sT+EFvG8Zs/le9bH4kIiuBTtWcekBV33Urdz8QqqoP1XCfzsBWIEZVS6qcCwTmAhtU9UURudsV219E5BxgPjBIVctri9UeQzUOVeW51Xt54qOd9O4Qwbxpw+neLtzpsEwtth/K5Y7Fm0nJKGD6D3rw63F9CQkKdDos4yMadac8EelGRd/CoBrO3wEMVNWZNZy/ALhXVX8iItuBcaqa7jq3Fxilqhm1xWDJouGpKr9/bwcvfZXKpYM7MWfiEHvs1EScLC7jjx9+w6tr0+jfuTV/m5xAn44RTodlfECD91mISG+3w/HAzlqKTwEWuV0rItKr8j1whdv1+4FLXOf6A6GA7QbjMFXlDx98w0tfpXLzD3rw92uHWaJoQsKCA5l95SDm35BIRl4Rl8/9gpe/SrXlz02deDvP4jER2SYiW4GxwB0AIpIoIi9UFhKROCAWWOV2rQAvi8jXwNdAZ+AR17lfATNEZAsVCeZGtf+jHaWqPLZ8J/O/2MeN58bxu8v6U5HjTVNzSf+OfHTnBZxzVjseWradm17aQEZ+kdNhGR9Xb4+hfIE9hmoYqsoTH+/in//5lutHdeeR8QMtUfgBVeWVNWn88cNvCA8J4rGrBjN2YHXdk8bfNfhjKNM8PPXv3fzzP99y7chu/P4KSxT+QkS44dw4Prj9B3SODGXmq8n85q2tnDhV6nRoxgdZsjC1+tvKPTz9aQrXJMbyh/GDbFa2H+rVIYKlt5zHLy46i9eT0rns6c/ZtD/b6bCMj7FkYWo0b/W3PLVyNxOHd+VPVw22ROHHgoMCuG9cPxbNGEVJmTLx2TX84z8p1vltvmPJwlRr4/5sHv9oF5cO7sTjE+ItUTQTo3q248M7zmfcoE488dEubl+8mZPFZU6HZXyAJQvzPQWnSrnr9c10ah3KYxPiCbRE0axEhrXgmSlDuXdcX97feoiJz37FwZyTTodlHGbJwnzP7Pd2sD+rkCcnDaF1aAunwzEOEBFuuagX829IZP/xQsY/8wUbUrOcDss4yJKF+R8fbTvC60np/OLCsxjZ01Yqbe4u7teRpb88l1YhQVz7/FoWrd/vdEjGIZYszHeO5hVx/9tbGdSlNXeO6eN0OMZH9OoQwbu//AGjerbj/re/5sF3t1FSVusybcYPWbIwAJSXK/e8uYWTJWX89ZqhBAfZ/xrmvyJbtuDFG89mxvk9eGVNGje+uN5242tm7BfBAPDKmlQ+33OMBy4bQK8OrZwOx/igoMAAHrhsAHMmxrN+XxZX/uNLUjIKnA7LNBJLFobdR/P50/KdXNyvA9eN7OZ0OMbHXZ0Yy6IZo8g7WcJP//Elq3fbGp/NgSWLZi6/qIQ7Fm+mVUgQj0+It6U8TJ0kxrXl3VvPo0tUGDe+uJ4Xv9xnE/j8nCWLZiyvqIRp/1rPnqP5/HnSEKIjQpwOyTQhXdu05K1fnMsl/Tvy+/d28NulX1vHtx+zZNFM5RWVMG3+er4+kMsz1w5jdN8OTodkmqDwkCCeu244t1x0FovWp/OLBckUldiMb39kyaIZyj1ZwvXz17P9UC7/mDqMcYNsWWpz5gIChHvH9WP2+IGs/CaD6S8nUVhsK9f6G0sWzUxuYQnXz1/HjkO5/GPqcNu/wNSb68+J489XD+Grb48xbf568opsaK0/sWTRjOQUFjN1/lp2Hs7n2euG88MBHZ0OyfiZicO7MnfKMDan5zD1+XVknyh2OiRTTyxZNBOZ+aeY+sI6dh8p4Lnrh3NJf0sUpmFcFt+ZedOGs+toPpPnrbUtW/2EV8lCRGaLyFYR2SwiK0Qkppoyo13nK19FInJllTJPi0iB23GIiLwuIikiss61h7c5A6rKkuQD/PCpVezJKOC5acMZ3c86s03DurhfR1668WzSswuZ9OwaW7XWD3jbspijqvGqmgC8DzxYtYCqfqaqCa4yFwOFwIrK8yKSCLSpctnNQLaq9gKeAh73Ms5mKT2rkGn/Ws89b26hV3QrPrz9BzbqyTSac3u159WbR3L8RDHXPLeG9KxCp0MyXvAqWahqntthOOBpVs5EYLmqFgKISCAwB7i3SrnxwMuu90uAS8Rmi9VZWbky/4t9jH1qNRvTsnlk/EDe+Pk59OoQ4XRoppkZ3r0Nr02vmO09ed5aSxhNmNd9FiLyqIikA1OppmVRxWRgkdvxrcAyVT1cpVwXIB1AVUuBXKDa9bJFZKaIJIlIUmamLTuQkpHPhH9+xez3dzCqZ1tW3H0h086Js53ujGMGd41k4fRRFJwqtYTRhImnKfoishKobnzlA6r6rlu5+4FQVX2ohvt0BrYCMapa4urfeAO4SFVLRaRAVVu5ym4DxqnqAdfxt8BIVT1WW6yJiYmalJRUa3382eb0HKbNX0dQYAAPXT6AK4bE2PIdxmdsO5jL1BfW0SokiEUzRtGtXUunQzIuIpKsqom1lfHYslDVMao6qJrXu1WKLgQm1HKrScBSVa0cfD0U6AWkiEgq0FJEUlznDgKxrkoEAZHAcU+xNmfJaVlc98I6oloGs+zW8xif0MUShfEpg7pEsnD6SE4UlzJ53hr2H7cWRlPi7Wio3m6H44GdtRSfgtsjKFX9QFU7qWqcqsYBha4ObYBlwA2u9xOBT9VWKavRur3HmTZ/PdERIbz+81F0bWP/YjO+qTJhFJaUcc28NaQdP+F0SKaOvO2zeExEtonIVmAscAdUjHASkRcqC7mGvsYCq+p43/lAO1dL427gN17G6be+SjnGjS9uoFNkKK/PHEXnyDCnQzKmVgNjInlt+iiKSsqYPG+tDattIjz2WTQlza3PYvXuTGa8kkRcu3AWTB9pq8aaJmXHoTyumbeG6IgQlsw6l7bhwU6H1GzVS5+F8U2f7jzK9JeTOCu6FYtmjrJEYZqcATGtmX/D2RzMPslNL66n4JQtPujLLFk0Qev2HmfWqxvp2ymC12aMtH+RmSZrRI+2/P3aYWw7lMesV5M5VWrLm/sqSxZNzLeZBcx8NZnYtmEsuHkkUS0tUZimbcyAjjw+IZ4vUo5x9+tbKCv3n0fj/iTI6QBM3WWdKOZnL20gKEB48cYRRLZs4XRIxtSLicO7kn2imEc//Iaoli34w5WDbOi3j7Fk0UQUlZQx85UkjuQWsWimTWgy/mfGBT05fqKYZ1d9S7vwYO4e29fpkIwbSxZNgKpy75KtJKVl8/drhzGsW9V1F43xD/eN60v2iWKe/jSFjpGhTB3Z3emQjIsliybgqX/vZtmWQ9w3rh+XxXd2OhxjGoyI8OhPB5GRX8SD726nW9uWnN872umwDNbB7fOWJB/g6U9TmHx2LLMu7Ol0OMY0uKDAAOZeO4zeHVpxy8KNpGTkOx2SwZKFT/tizzHuf3srP+jVntnW4WeakVYhQcy/8WxCggK56aUNHC845XRIzZ4lCx+1du9xpr+ygbOiW/H3qcNoEWh/VKZ56RIVxgs3JJKRd4qf2xwMx9kvkA9KTsviZy9tILZNSxZMH0lkmA2RNc1TQmwUT12TQFJaNvct2Yo/LU/U1Fiy8DGb03O48V8b6Ng6lIXTR9K+lS3jYZq3Swd35tc/6ss7mw/x9Ccpni8wDcJGQ/mQbQdzmTZ/HW3Cg3ltxkg6tA51OiRjfMItF53F3swTPLVyNz2iw7liSIzTITU71rLwETuP5HHd/HVEhLbgtRkjbalxY9yICH+8ahAj4try6ze3sPVAjtMhNTuWLHxASkY+U59fR2hQIItm2OZFxlQnJCiQf143jPatQpj5SjIZeUVOh9SsWLJwWHm58suFmxARXpsx0pbxMKYW7VqF8MINieQVlTDj1WSKSmyEVGOxZOGwj7cfYdfRfP7vJ/3pGd3K6XCM8Xn9O7fmyUkJbEnP4bdvf20jpBqJt3twzxaRrSKyWURWiMj3ep1EZLTrfOWrSESurFLmaREpcDu+W0R2uO79iYj45QIxqsrcT1Po2T6cn8Rbh50xdTVuUCd+9cM+vL3pIPNW73U6nGbB25bFHFWNV9UE4H3gwaoFVPUzVU1wlbkYKARWVJ4XkUSg6sp4m4BEVY0HlgBPeBmnT/rkmwx2HM7jltG9CAyw2dnGnI5bL+7FZfGdeeyjnXy686jT4fg9r5KFqua5HYYDntqDE4HlqloIICKBwBzg3ir3/ayyDLAW6OpNnL6oolWxh9i2YYxPsFaFMadLRPjzxCEMjGnN7Ys2s+eorSHVkLzusxCRR0UkHZhKNS2LKiYDi9yObwWWqerhWq65GVjuXZS+Z/WeY2w5kMstF/WypTyMOUNhwYHMuz6R0BaBTH8liZzCYqdD8lsef6VEZKWIbKvmNR5AVR9Q1VhgIRU//jXdpzMwGPjYdRwDXA3MreWa64BEKlofNZWZKSJJIpKUmZnpqTo+QVWZ+8keYiJDmTDM7xpNxjSqmKgwnrt+OIdyTnLbok2UlpU7HZJf8pgsVHWMqg6q5vVulaILgQm13GoSsFRVS1zHQ4FeQIqIpAItReS7ufwiMgZ4ALhCVWtcclJV56lqoqomRkc3jXXv1+w9TlJaNrMuOovgIGtVGOOt4d3bMHv8ID7fc4w5H+9yOhy/5NVyHyLSW1X3uA7HAztrKT4FuL/yQFU/ADq53atAVXu53g8FngPGqWqGNzH6ormfpBAdEcKkxFinQzHGb0we0Y3th/J4bvVeBsS0ZnxCF6dD8ive/rP2Mdcjqa3AWOAOqBjhJCIvVBYSkTggFlhVx/vOAVoBb7qG2y7zMk6fkZSaxZq9x/n5BT0JbRHodDjG+JUHLx/AiB5tuXfJVrYdzHU6HL8i/jShJTExUZOSkpwOo1bT/rWebQdz+eK+0bQMtnUcjalvxwpOccXcLwBYdtsPbOXmOhCRZFVNrK2MPTBvRJvTc1i9O5Pp5/ewRGFMA2nfKoTnrk/k+Iliblm4kRLr8K4Xliwa0TOf7iEyrAXTzolzOhRj/NrgrpE8PiGe9fuymP3+DqfD8QuWLBrJyh1HWflNBj87rwetQqxVYUxDu3JoF2ac34NX1qTx2rr9TofT5FmyaASpx05w1xubGdSlNT+/sKfT4RjTbNw3rh8X9Y3m/97dxud7msY8LF9lyaKBnSwuY9aCZAJE+OfU4TYCyphGFBQYwNwpQ+ndoRW3LNhoS4J4wZJFA1JVfvfONnYdzeevkxOIbWt7VRjT2CJCWzD/xrMJDQ7kppc2cKygxjm+phaWLBrQa+v389bGA9x2cW9G9+3gdDjGNFtdosJ4YVoixwpOMeOVJNs06QxYsmggW9Jz+P2yHVzQJ5o7LuntdDjGNHtDYqP46zUJbNqfwz1vbqG83H/mmDUGSxYNIMs1vjs6IoS/XZNge1UY4yPGDerMb37cj/e3HubJf+92OpwmxcZw1rOycuWOxZvIzD/Fm7POoU14sNMhGWPc/PyCnqQeO8Ezn6UQ1z6cicNt5ee6sJZFPXtt/X4+33OMh68YyJDYKKfDMcZUISLMvnIQ557Vjt++/TWb9mc7HVKTYMmiHqkqL3+VypCukUwZYSvKGuOrWgQG8Pdrh9GhdQizFiSTkV/kdEg+z5JFPVq7N4uUjAKuG9UdEeunMMaXtQkPZt71ieSdLOWWBRspLrU1pGpjyaIeLViXRmRYCy4fYntqG9MUDIhpzZyr40lKy+b37213OhyfZsminmTkF/HxtiNMHN7VZmkb04T8JD6GX1x0FgvX7bc1pGphyaKevL4+ndJyZerIbk6HYow5TfeM7cuFfaJ5aNk2ktOynA7HJ1myqAdl5cqi9fs5r1c7eka3cjocY8xpCgwQnp48lC5RYcxasJEjudbhXZUli3rw6c4MDuUWcf2o7k6HYow5Q5EtWzBvWiKFp0r5+YJkWxKkCq+ShYjMFpGtrn2yV4jI93p2RWS063zlq0hErqxS5mkRKajm2gkioiJS63Z/TluwNo2OrUMY07+j06EYY7zQp2MET16TwJb0HO5/+2v8adtpb3nbspijqvGqmgC8DzxYtYCqfqaqCa4yFwOFwIrK865E0KbqdSISAdwBrPMyxga1/3ghq/dkMvnsbgQFWkPNmKbuRwM7cc/YPizddJBnV+11Ohyf4dWvm6rmuR2GA57S8ERguaoWAohIIDAHuLeasrOBxwGffni4cH0aASJMGWEd28b4i1+O7sXlQ2J44uOd/HvHUafD8Qle/1NYRB4VkXRgKtW0LKqYDCxyO74VWKaqh6vccxgQq6of1OH7Z4pIkogkZWY27k5YRSVlvLEhnTH9O9ApMrRRv9sY03BEhDkT4xncJZI7F29i55E8zxf5OY/JQkRWisi2al7jAVT1AVWNBRZS8eNf0306A4OBj13HMcDVwNwq5QKAJ4Ff1aUCqjpPVRNVNTE6Oroul9Sb5dsOk11YwvWj4hr1e40xDS+0RSDPT0ukVWgQN7+UxPFmvmmSx2ShqmNUdVA1r3erFF0ITKjlVpOApapa4joeCvQCUkQkFWgpIilABDAI+I/r81HAMl/s5F6wdj892odz7lntnA7FGNMAOrYOZd71FZsmzVqQ3KyXBPF2NJT7rj7jgZ21FJ+C2yMoVf1AVTupapyqxgGFqtpLVXNVtb3b52uBK1Q1yZtY69s3h/NITstm6shuBNh+Fcb4rSGxUcy5eggbUrP53TvNd4SUt30Wj7keSW0FxlIxegkRSRSRFyoLiUgcEAus8vL7fMbCdWmEBAXYWvjGNANXDInhtot78UbSAV5b3zyXBPFq8yNVrfaxk6sVMN3tOBXo4uFe1U59VtWLzjzChqGqrNyRwZj+HYlqaZsbGdMc3DWmD5vTc5j9/g5G9mhHrw7Na7UGmxhwBg7mnORIXhEjerR1OhRjTCMJCBD+cvUQwloEcsfiTc2u/8KSxRlITqvYWWt49+/NJTTG+LEOrUN5fEI82w/l8Zd/73I6nEZlyeIMJKVm0yokiH6dIpwOxRjTyMYO7MSUEd2Yt3ovX317zOlwGo0lizOwITWLod2ibHkPY5qp//tJf3q0C+fu17eQU1jsdDiNwn7tTlNeUQm7jubbIyhjmrGWwUH8bfJQjhWc4rdLm8dwWksWp2nT/hxU4ew469w2pjkb3DWSu8f24cOvj7Ak+YDT4TQ4SxanKTk1i8AAISE2yulQjDEO+/kFZzGyR1seXradtOMnnA6nQVmyOE0bUrPp3zmC8BCvpqgYY/xAYIDw5DUJBAQIty/eTEmZ/w6ntWRxGkrKytmcnkNid3sEZYyp0CUqjMeuimdLeg5/WbHb6XAajCWL0/DN4TxOlpSRGGed28aY/7osvjNTRsTy7Kpv+XxP426V0FgsWZyGDakVk/GsZWGMqerBnwykd4dW3PX6FjLz/W85c0sWpyE5LYsuUWG20ZEx5nvCggOZe+1Q8otK+NWbWygv96/htJYs6khVSUrN5mx7BGWMqUG/Tq353U8GsHp3Ji984V/7d1uyqKP0rJNk5J9iuM2vMMbU4rqR3fjRwI488dEutqTnOB1OvbFkUUdJaVkAJNrMbWNMLUSExyfE0yEihNsXbyK/qMTzRU2AJYs6SkrLJiI0iD4dbfFAY0ztoloG87cpQ0nPKuT/3tnmF8uBWLKoo6TULIZ1a0OgbaFqjKmDs+PacueYPryz+RBvbTzodDhe83YP7tkislVENovIChGJqabMaNf5yleRiFxZpczTIlJQ5bNJIrJDRLaLyGvexOmt3MISdh8tsEdQxpjT8svRvRjVsy3/9842vs0s8HyBD/O2ZTFHVeNVNQF4H3iwagFV/UxVE1xlLgYKgRWV50UkEfifX2ER6Q3cD5ynqgOBO72M0ysb97vmV1jntjHmNAQGCH+9ZiihLQK47bVNFJWUOR3SGfMqWahqntthOODpwdxEYLmqFgKISCAwB7i3SrkZwN9VNdv1PRnexOmtDalZBNnigcaYM9ApMpQ/Xz2EHYfzeGz5TqfDOWNe91mIyKMikg5MpZqWRRWTgUVux7cCy1T1cJVyfYA+IvKliKwVkXHexumNpLRsBsa0Jiw40MkwjDFN1CX9O/Kz83rw0lep/HvHUafDOSMek4WIrBSRbdW8xgOo6gOqGgsspOLHv6b7dAYGAx+7jmOAq4G51RQPAnoDFwFTgOdFJKqG+84UkSQRScrMrP81WYpLy9mSnsNwW+LDGOOF+37cl4Exrfn1ki0czj3pdDinzWOyUNUxqjqomte7VYouBCbUcqtJwFJVrRx0PBToBaSISCrQUkRSXOcOUNHiKFHVfcBuKpJHdfHNU9VEVU2Mjo72VJ3Ttu1QLqdKy23mtjHGKyFBgTxz7TBKSsu5Y9FmSpvYcubejoZy/wEfD9T2QG4Kbo+gVPUDVe2kqnGqGgcUqmov1+l3qGhVICLtqXgs5cjc+WTX4oHDLVkYY7zUo304s68cxPrULOZ+muL5Ah/ibZ/FY65HUluBscAdUDHCSUReqCwkInFALLCqjvf9GDguIjuAz4Bfq+pxL2M9I0lpWXRr25IOEbZ4oDHGe1cN68pVQ7sw99M9rNvryM/aGRF/mFlYKTExUZOSkurtfqpK4h9WcmHfaJ6clFBv9zXGNG8Fp0q57OnPKS1TPrrzfCJCWzgaj4gkq2pibWVsBnctDuUWcfxEMUO72SMoY0z9aRUSxJOTEjice5JH3tvhdDh1YsmiFgezK0YsdG/b0uFIjDH+Znj3NvziorN4M/kAK7YfcTocjyxZ1KJyeFtn2+zIGNMA7rikDwNjWnP/219zrMC3d9ezZFGLI7lFALYznjGmQQQHBfDUNQnknyrlN2997dOr01qyqMXh3CJahQQ53vlkjPFffTpGcO+P+rLym6O8kZTudDg1smRRi8O5J+0RlDGmwf3svB6c07Mdj7y3g/3HC50Op1qWLGpxJLfIHkEZYxpcQIDw50lDCBDhV29upqzc9x5HWbKoxeHcImtZGGMaRZeoMB6+YiAbUrN5/nNHFqyolSWLGhSXlpNZcIpOkWFOh2KMaSauGtaFcQM78eS/d5OS4VubJVmyqEFGfhGqEGMtC2NMIxERHrlyIGEtArnvra0+9TjKkkUNbNisMcYJHSJCeejyASSnZfPKmlSnw/mOJYsaHHYli872GMoY08h+OrQLF/WN5omPdvnM6ChLFjX4bvZ2lLUsjDGNS0T4408HExgg3L90q09M1rNkUYPDuUWEBwcSERLkdCjGmGYoJiqM+y/tx5cpx3l9g/OT9SxZ1KByjoWIOB2KMaaZmnJ2N0b1bMujH3zj+FaslixqUDHHwvorjDHOCQgQHp8QT0l5Ob9bus3Rx1GWLGpgS30YY3xB93bh3DO2L5/szGDZlkOOxWHJoholZeVk5J+yZGGM8Qk3ndeDod2ieHjZdo47tJS5V8lCRGaLyFYR2SwiK0Qkppoyo13nK19FInJllTJPi0iB23E3EflMRDa57n+pN3Gersz8U6his7eNMT4hMEB4YkI8+UWl/Gn5Tkdi8LZlMUdV41U1AXgfeLBqAVX9TFUTXGUuBgqBFZXnRSQRqLpv6e+AN1R1KDAZ+IeXcZ6W/86xsJaFMcY39O4YwcwLerIk+QBr9x5v9O/3Klmoap7bYTjgqfdlIrBcVQsBRCQQmAPcW/XWQGvX+0igUR/U2RwLY4wvuu3i3sS2DeOBpV9TXFreqN/tdZ+FiDwqIunAVKppWVQxGVjkdnwrsExVD1cp9zBwnYgcAD4Ebqvl+2eKSJKIJGVmZp52/NWpXOqjc2t7DGWM8R1hwYE8csUgvs080egr03pMFiKyUkS2VfMaD6CqD6hqLLCQih//mu7TGRgMfOw6jgGuBuZWU3wK8JKqdgUuBV4VkWpjVdV5qpqoqonR0dGeqlMnh3OLCGsRSOswm5BnjPEto/t14NLBnXj6kz2kHT/RaN/rMVmo6hhVHVTN690qRRcCE2q51SRgqaqWuI6HAr2AFBFJBVqKSIrr3M3AG67vXwOEAu3rXCsvHXHtY2ET8owxvujBnwykRWAAD767vdHmXng7Gqq32+F4oLZu+im4PYJS1Q9UtZOqxqlqHFCoqr1cp/cDl7i+oz8VyaJ+njHVwaHck9ZfYYzxWZ0iQ/nV2D6s2p3Jh18faZTv9LbP4jHXI6mtwFjgDqgY4SQiL1QWEpE4IBZYVcf7/gqYISJbqEgwN2ojTl08kltEJ+uvMMb4sGnnxDGoS2t+/9528opKPF/gJW9HQ01wPZKKV9XLVfWg6/MkVZ3uVi5VVbuoao3d96rayu39DlU9T1WHuIbdrqjpuvpWahPyjDFNQGBAxcq0mQWneHLF7gb/PpvBXcWxgmLKytU2PTLG+Lz4rlFMG9WdV9aksvVAToN+lyWLKg655ljEWJ+FMaYJ+NWP+tKjfTgHsht2VVobG1rFd9upWp+FMaYJaB3aghV3XUhgQMOO3rSWRRW21Icxpqlp6EQBliy+50juSUKCAohq2cLpUIwxxmdYsqjiUG4RMVFhNiHPGGPcWLKoomKOhT2CMsYYd5Ysqqhc6sMYY8x/WbJwU1auHMkrsqU+jDGmCksWbo4VnHJNyLNhs8YY486ShZvvhs1an4UxxvwPSxZujrhmb9tSH8YY878sWbg5lFPRsoiJssdQxhjjzpKFmyN5RQQHBdDGJuQZY8z/sGTh5rDtkGeMMdWyZOHmSO5Jm5BnjDHVsGTh5lBOkfVXGGNMNSxZuJSXK0fzimwklDHGVMOrZCEis0Vkq4hsFpEVIhJTTZnRrvOVryIRudJ17iUR2ed2LsH1uYjI0yKS4rr/MG/irItjJ05RWq621IcxxlTD25bFHNf+2wnA+8CDVQuo6meufbQTgIuBQsB9T+1fV55X1c2uz34M9Ha9ZgL/9DJOj/676ZElC2OMqcqrZKGqeW6H4YB6uGQisFxVCz2UGw+8ohXWAlEi0tmLUD2yORbGGFMzr/ssRORREUkHplJNy6KKycCiKp896nrU9JSIhLg+6wKku5U54Pqsuu+fKSJJIpKUmZl5BjWoYLO3jTGmZh6ThYisFJFt1bzGA6jqA6oaCywEbq3lPp2BwcDHbh/fD/QDzgbaAvedbgVUdZ6qJqpqYnR09Ole/p3DeUUEBwbQtmXwGd/DGGP8VZCnAqo6po73Wgh8CDxUw/lJwFJVLXG792HX21Mi8iJwj+v4IBDrdm1X12cN5khuER0jQwhohL1sjTGmqfF2NFRvt8PxwM5aik+hyiOoyn4IqZgyfSWwzXVqGTDNNSpqFJDrllgaxOGcIjrb0uTGGFMtjy0LDx4Tkb5AOZAGzAIQkURglqpOdx3HUdFSWFXl+oUiEg0IsLnyeipaKJcCKVSMnrrJyzg9Opx3kmHd2jT01xhjTJPkVbJQ1Qk1fJ4ETHc7TqWaDmpVvbiG6xX4pTexnY7ycuVo7inr3DbGmBrYDG4gq7CY4rJy2/TIGGNqYMmCiv4KgM42x8IYY6plyQI47JpjYUt9GGNM9SxZULHpEdiEPGOMqYklCyrWgxo7oCPtw0M8FzbGmGbI26GzfmHswE6MHdjJ6TCMMcZnWcvCGGOMR5YsjDHGeGTJwhhjjEeWLIwxxnhkycIYY4xHliyMMcZ4ZMnCGGOMR5YsjDHGeCQVq4H7BxHJpGJfjdq0B441Qji+qDnXHZp3/Ztz3aF5178ude+uqrXuS+1XyaIuRCRJVROdjsMJzbnu0Lzr35zrDs27/vVVd3sMZYwxxiNLFsYYYzxqjslintMBOKg51x2ad/2bc92hede/Xure7PosjDHGnL7m2LIwxhhzmixZGGOM8civkoWIjBORXSKSIiK/qeZ8iIi87jq/TkTi3M7d7/p8l4j8qFEDrwdnWncRaScin4lIgYg80+iB1wMv6v5DEUkWka9d/7240YOvB17Uf4SIbHa9tojITxs9eC9583fedb6b6//9exot6HrkxZ99nIicdPvzf9bjl6mqX7yAQOBboCcQDGwBBlQpcwvwrOv9ZOB11/sBrvIhQA/XfQKdrlMj1T0c+AEwC3jG6bo0ct2HAjGu94OAg07Xp5Hr3xIIcr3vDGRUHjeFlzd1dzu/BHgTuMfp+jTyn30csO10vs+fWhYjgBRV3auqxcBiYHyVMuOBl13vlwCXiIi4Pl+sqqdUdR+Q4rpfU3HGdVfVE6r6BVDUeOHWK2/qvklVD7k+3w6EiUhT24jdm/oXqmqp6/NQoKmNdvHm7zwiciWwj4o/+6bIq/qfLn9KFl2AdLfjA67Pqi3j+kuSC7Sr47W+zJu6N3X1VfcJwEZVPdVAcTYUr+ovIiNFZDvwNTDLLXk0BWdcdxFpBdwH/L4R4mwo3v6/30NENonIKhE539OXBXkfrzFNm4gMBB4HxjodS2NT1XXAQBHpD7wsIstVtam2Mk/Hw8BTqlpwhv/QbuoOA91U9biIDAfeEZGBqppX0wX+1LI4CMS6HXd1fVZtGREJAiKB43W81pd5U/emzqu6i0hXYCkwTVW/bfBo61+9/Nmr6jdAARV9N02FN3UfCTwhIqnAncBvReTWBo63vp1x/V2P3I8DqGoyFX0ffWr7Mn9KFhuA3iLSQ0SCqejMWValzDLgBtf7icCnWtHbswyY7Bo50APoDaxvpLjrgzd1b+rOuO4iEgV8APxGVb9srIDrmTf17+H6AUFEugP9gNTGCbtenHHdVfV8VY1T1Tjgr8AfVbWpjQb05s8+WkQCAUSkJxW/eXtr/Tane/TreXTApcBuKrLkA67PHgGucL0PpWLkQwoVyaCn27UPuK7bBfzY6bo0ct1TgSwq/mV5gCojKnz9daZ1B34HnAA2u706OF2fRqz/9VR07m4GNgJXOl2Xxqp7lXs8TBMcDeXln/2EKn/2l3v6LlvuwxhjjEf+9BjKGGNMA7FkYYwxxiNLFsYYYzyyZGGMMcYjSxbGGGM8smRhjDHGI0sWxhhjPPp/9TBeWKysHIQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha = []\n",
    "error = []\n",
    "\n",
    "for i in range(1,50):\n",
    "    alpha.append(i/1000)\n",
    "    lml = Lasso(alpha=(i/1000))\n",
    "    error.append(np.mean(cross_val_score(lml, X_train, y_train, scoring = 'neg_mean_absolute_error',cv=5)))\n",
    "\n",
    "plt.plot(alpha,error)\n",
    "err = list(zip(alpha,error))\n",
    "from operator import itemgetter\n",
    "err = sorted(err,key=itemgetter(1))[-1]\n",
    "best_alpha = err[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fit and cross-validate the model using the given value for alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.76186039 -3.82433762 -3.82287457 -3.62039539 -3.64992141]\n",
      "-3.7358778743455914\n"
     ]
    }
   ],
   "source": [
    "lm_l = Lasso(alpha=best_alpha)\n",
    "lm_l.fit(X_train,y_train)\n",
    "lasso_res = cross_val_score(lm_l, X_train, y_train, scoring = 'neg_mean_absolute_error',cv=5)\n",
    "print(lasso_res)\n",
    "print(np.mean(lasso_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a slight improvement compared to our base lasso and linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Random Forest Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will follow the same procedure as the previous model:\n",
    "1. Fit a model with only default parameters \n",
    "2. Tune the model using cross-validation \n",
    "3. Fit the final model with tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.10018956 -3.34563122 -3.24240945 -3.17474812 -3.14141951]\n",
      "-3.2008795746443055\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "rf_scores = cross_val_score(rf, X_train, y_train,scoring = 'neg_mean_absolute_error',cv=5)\n",
    "print(rf_scores)\n",
    "print(np.mean(rf_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This already outperforms the previous models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now tune the model using a RandomizedSearch, which was chosen over GridSearch since it yielded similar performance with less computational time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   55.4s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  2.8min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rf_hyperparameters = {\n",
    "        'n_estimators': [120,150,180],\n",
    "        'max_depth': [3,5,10],\n",
    "        'min_samples_split': [3,5,7],\n",
    "        'min_samples_leaf':[5,8,11],\n",
    "        'max_features': ['auto','sqrt'],\n",
    "        }\n",
    "random_cv_rf = RandomizedSearchCV(estimator=rf,\n",
    "            param_distributions=rf_hyperparameters,\n",
    "            cv=5, n_iter=50,\n",
    "            scoring = 'neg_mean_absolute_error',n_jobs=-1,\n",
    "            verbose=5,\n",
    "            return_train_score = True,\n",
    "            random_state=42\n",
    "        )\n",
    "random_cv_rf.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(max_depth=10, min_samples_leaf=5, min_samples_split=3,\n",
      "                      n_estimators=150)\n"
     ]
    }
   ],
   "source": [
    "best_rf = random_cv_rf.best_estimator_\n",
    "print(best_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.06210197 -3.31434088 -3.20004481 -3.15168383 -3.08008535]\n",
      "-3.1616513679428677\n"
     ]
    }
   ],
   "source": [
    "rf_tuned_scores = cross_val_score(best_rf, X_train, y_train, scoring = 'neg_mean_absolute_error',cv=5)\n",
    "print(rf_tuned_scores)\n",
    "print(np.mean(rf_tuned_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. XGBoost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost (Extreme Gradient Boosting) is likely the most popular predictive algorithm for structured data at the moment. The procedure for XGBoost will be the same as the previous two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.2867294  -3.48275902 -3.37105822 -3.30147888 -3.35968413]\n",
      "-3.3603419308099136\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb = XGBRegressor()\n",
    "xgb.fit(X_train,y_train)\n",
    "xgb_res = cross_val_score(xgb, X_train, y_train, scoring = 'neg_mean_absolute_error',cv=5)\n",
    "print(xgb_res)\n",
    "print(np.mean(xgb_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   59.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                          colsample_bylevel=1,\n",
       "                                          colsample_bynode=1,\n",
       "                                          colsample_bytree=1, gamma=0,\n",
       "                                          gpu_id=-1, importance_type='gain',\n",
       "                                          interaction_constraints='',\n",
       "                                          learning_rate=0.300000012,\n",
       "                                          max_delta_step=0, max_depth=6,\n",
       "                                          min_child_weight=1, missing=nan,\n",
       "                                          monotone_constraints='()',\n",
       "                                          n_estimators=100, n_jobs=4,\n",
       "                                          num_par...\n",
       "                                          tree_method='exact',\n",
       "                                          validate_parameters=1,\n",
       "                                          verbosity=None),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'base_score': [0.75, 1, 1.25],\n",
       "                                        'booster': ['gbtree', 'gblinear'],\n",
       "                                        'learning_rate': [0.01, 0.03, 0.05],\n",
       "                                        'max_depth': [2, 5, 10],\n",
       "                                        'min_child_weight': [0.4, 0.7, 1],\n",
       "                                        'n_estimators': [50, 75, 100]},\n",
       "                   random_state=42, return_train_score=True,\n",
       "                   scoring='neg_mean_absolute_error', verbose=5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_hyperparameters = {\n",
    "        'n_estimators': [50, 75, 100],\n",
    "        'max_depth': [2, 5, 10],\n",
    "        'learning_rate': [0.01, 0.03, 0.05],\n",
    "        'min_child_weight':[0.4, 0.7, 1],\n",
    "        'booster': ['gbtree','gblinear'],\n",
    "        'base_score': [0.75, 1, 1.25]\n",
    "        }\n",
    "\n",
    "random_cv_xgb = RandomizedSearchCV(estimator=xgb,\n",
    "            param_distributions=xgb_hyperparameters,\n",
    "            cv=5, n_iter=50,\n",
    "            scoring = 'neg_mean_absolute_error',n_jobs=-1,\n",
    "            verbose=5,\n",
    "            return_train_score = True,\n",
    "            random_state=42\n",
    "        )\n",
    "random_cv_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.06321123 -3.31307183 -3.19989155 -3.0590898  -3.0894286 ]\n",
      "-3.1449386016428234\n"
     ]
    }
   ],
   "source": [
    "best_xgb = random_cv_xgb.best_estimator_\n",
    "xgb_tuned_res = cross_val_score(best_xgb, X_train, y_train, scoring = 'neg_mean_absolute_error',cv=5)\n",
    "print(xgb_tuned_res)\n",
    "print(np.mean(xgb_tuned_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results from cross-validation are very similar to random forest, with a slightly better average error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Making predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lm = lm.predict(X_test)\n",
    "pred_lml = lm_l.predict(X_test)\n",
    "pred_rf_base = rf.predict(X_test)\n",
    "pred_rf_tuned = best_rf.predict(X_test)\n",
    "pred_xgb_base = xgb.predict(X_test)\n",
    "pred_xgb_tuned = best_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the results, we will use mean absolute error. We will also divide the predicted values by the associated salary cap factor for that year which we used earlier. This will ensure our predictions will be in the same reference as the unaltered test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "# Add the factor column back\n",
    "X_test['Factor'] = X_test['Date'].map(caps)\n",
    "# Fine mean absolute error of the predicted values divided by the factor\n",
    "lm_results = mean_absolute_error(pred_lm/X_test['Factor'],y_test)\n",
    "lml_results = mean_absolute_error(pred_lml/X_test['Factor'],y_test)\n",
    "rf_base_results = mean_absolute_error(pred_rf_base/X_test['Factor'],y_test)\n",
    "rf_tuned_results = mean_absolute_error(pred_rf_tuned/X_test['Factor'],y_test)\n",
    "xgb_base_results = mean_absolute_error(pred_xgb_base/X_test['Factor'],y_test)\n",
    "xgb_tuned_results = mean_absolute_error(pred_xgb_tuned/X_test['Factor'],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean Absolute Error (In millions of $)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>3.015034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>2.997216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Base</td>\n",
       "      <td>2.609782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest Tuned</td>\n",
       "      <td>2.608315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost Base</td>\n",
       "      <td>2.674901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost Tuned</td>\n",
       "      <td>2.612677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Mean Absolute Error (In millions of $)\n",
       "0    Linear Regression                                3.015034\n",
       "1     Lasso Regression                                2.997216\n",
       "2   Random Forest Base                                2.609782\n",
       "3  Random Forest Tuned                                2.608315\n",
       "4         XGBoost Base                                2.674901\n",
       "5        XGBoost Tuned                                2.612677"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_all = pd.DataFrame({'Model':['Linear Regression','Lasso Regression','Random Forest Base','Random Forest Tuned','XGBoost Base','XGBoost Tuned'],\n",
    "                'Mean Absolute Error (In millions of $)': [lm_results, lml_results,rf_base_results,rf_tuned_results,xgb_base_results,xgb_tuned_results]})\n",
    "results_all "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model was the tuned Random Forest, with a mean absolute error equal to $2.6 million. The tuned XGBoost performed very similarly and both significantly outperformed the base regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
